[{"content":"This website is an experiment of sorts. Over the last year or so, I have been playing around with logseq as a note taking tool. Looking for a way to better share my notes, I have found the Schrodinger plugin by Aryan Sawhney.\nThis is what happened next.\n","permalink":"https://vonhartz.info/pages/welcome/","summary":"This website is an experiment of sorts. Over the last year or so, I have been playing around with logseq as a note taking tool. Looking for a way to better share my notes, I have found the Schrodinger plugin by Aryan Sawhney.\nThis is what happened next.","title":"Welcome"},{"content":"This is a test/examle post.\nHow to\n\u0026gt;\u0026gt;\u0026gt; import torch \u0026gt;\u0026gt;\u0026gt; import matplotlib.pyplot as plt \u0026gt;\u0026gt;\u0026gt; def plot(pr, sm, po, channel): ... for i, d in enumerate([pr[channel], sm[channel], po[channel], (sm*pr)[channel]]): ... plt.subplot(1, 4, i+1) ... plt.imshow(d) ... plt.show() \u0026gt;\u0026gt;\u0026gt; pr = torch.load(\u0026#39;/export/hartzj/TakeLidOffSaucepan/demos_gt/encodings/dcm_10_keypoints_encoder-resnet101bs128split9010/new_ego/2022_05_03-14_34_44/cam_w_prior/80.dat\u0026#39;) \u0026gt;\u0026gt;\u0026gt; po = torch.load(\u0026#39;/export/hartzj/TakeLidOffSaucepan/demos_gt/encodings/dcm_10_keypoints_encoder-resnet101bs128split9010/new_ego/2022_05_03-14_34_44/cam_w_post/80.dat\u0026#39;) \u0026gt;\u0026gt;\u0026gt; sm = torch.load(\u0026#39;/export/hartzj/TakeLidOffSaucepan/demos_gt/encodings/dcm_10_keypoints_encoder-resnet101bs128split9010/new_ego/2022_05_03-14_34_44/cam_w_sm/80.dat\u0026#39;) Results for sigma=2\nChannels: 10, 2, 14\nWhile on 2 it resolves the multimodality, on channel 10 it does not manage to do it. On Channel 14 it further manages to sharpen the cluster, but sometimes it also fails to do that.\nI think the noise component in the motion model is too strong.\nIf you look at successive frames of the same channel, sometimes multi-modalities would spring up later in the trajectory.\nProblem was that the softmax was stored as the prior for the next step, not the posterior.\nFixing it, resolves that and does in fact improve kp localization.\nThe numerical effect is not very large though.\nCould be that collapse of multi-modalities is not correct, but stable across a trajectory. In that case should still see improvement in policy learning.\nBut, I also observed some keypoints still moving. Could be that this only happens when the kp is moving outside too much.\nCould be that smaller sigma helps.\n","permalink":"https://vonhartz.info/pages/discrete-filter-debug/","summary":"This is a test/examle post.\nHow to\n\u0026gt;\u0026gt;\u0026gt; import torch \u0026gt;\u0026gt;\u0026gt; import matplotlib.pyplot as plt \u0026gt;\u0026gt;\u0026gt; def plot(pr, sm, po, channel): ... for i, d in enumerate([pr[channel], sm[channel], po[channel], (sm*pr)[channel]]): ... plt.subplot(1, 4, i+1) ... plt.imshow(d) ... plt.show() \u0026gt;\u0026gt;\u0026gt; pr = torch.load(\u0026#39;/export/hartzj/TakeLidOffSaucepan/demos_gt/encodings/dcm_10_keypoints_encoder-resnet101bs128split9010/new_ego/2022_05_03-14_34_44/cam_w_prior/80.dat\u0026#39;) \u0026gt;\u0026gt;\u0026gt; po = torch.load(\u0026#39;/export/hartzj/TakeLidOffSaucepan/demos_gt/encodings/dcm_10_keypoints_encoder-resnet101bs128split9010/new_ego/2022_05_03-14_34_44/cam_w_post/80.dat\u0026#39;) \u0026gt;\u0026gt;\u0026gt; sm = torch.load(\u0026#39;/export/hartzj/TakeLidOffSaucepan/demos_gt/encodings/dcm_10_keypoints_encoder-resnet101bs128split9010/new_ego/2022_05_03-14_34_44/cam_w_sm/80.dat\u0026#39;) Results for sigma=2\nChannels: 10, 2, 14\nWhile on 2 it resolves the multimodality, on channel 10 it does not manage to do it.","title":"Discrete Filter Debug"},{"content":" Currently PhD student at the neurorobotics and robot learning labs, University of Freiburg.\nSpecialized in Reinforcement learning, algorithms, cognitive computation.\nResearch interests Sequential decision problems, policy learning, embodied cognition.\nEducation 2020 - 2022 MSc Computer Science, University of Freiburg (Germany) Minor: Neuroscience\n2019 - 2020 Erasmus stay at ESIEE Paris (France)\n2015 - 2019 BSc Computer Science, University of Freiburg (Germany) Minor: Cognitive Science\nPublications Journals Forthcoming von Hartz, Jan Ole, and Chisari, Eugenio and Welschehold, Tim and Valada, Abhinav. ”The Treachery of Images: Re-Imagining Representation Learning as Scene Representation using Bayes Filters”.\n2018 Dames, Hannah and von Hartz, Jan Ole and Kantz, Mario and Riesterer, Nicolas and Ragni, Marco (2018), “Multinomial Processing Models for Syllogistic Reasoning: A Comparison”, Paper presented at the 40th annual cognitive science society meeting http://mindmodeling.org/cogsci2018/papers/0305/0305.pdf\nWorkshops 2022 von Hartz, Jan Ole, and Chisari, Eugenio and Welschehold, Tim Valada, Abhinav. ”Self-Supervised Learning of Multi-Object Keypoints for Robotic Manipulation.” In ICRA 2022 Workshop: Reinforcement Learning for Contact-Rich Manipulation.\nCommunity involvement Reviewer Duties 2022 NeurIPS Datasets and Benchmarks\n","permalink":"https://vonhartz.info/pages/cv/","summary":"Currently PhD student at the neurorobotics and robot learning labs, University of Freiburg.\nSpecialized in Reinforcement learning, algorithms, cognitive computation.\nResearch interests Sequential decision problems, policy learning, embodied cognition.\nEducation 2020 - 2022 MSc Computer Science, University of Freiburg (Germany) Minor: Neuroscience\n2019 - 2020 Erasmus stay at ESIEE Paris (France)\n2015 - 2019 BSc Computer Science, University of Freiburg (Germany) Minor: Cognitive Science\nPublications Journals Forthcoming von Hartz, Jan Ole, and Chisari, Eugenio and Welschehold, Tim and Valada, Abhinav.","title":"Curriculum vitae"}]